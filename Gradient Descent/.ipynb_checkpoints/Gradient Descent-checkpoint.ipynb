{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+----------+--------+--------------+----------------+----------------+--------------+-------+\n",
      "| indep | length | diameter | height | whole_weight | Shucked_weight | viscera_weight | shell_weight | rings |\n",
      "+-------+--------+----------+--------+--------------+----------------+----------------+--------------+-------+\n",
      "|  1.0  | 0.455  |  0.365   | 0.095  |    0.514     |     0.2245     |     0.101      |     0.15     |  15.0 |\n",
      "|  1.0  |  0.35  |  0.265   |  0.09  |    0.2255    |     0.0995     |     0.0485     |     0.07     |  7.0  |\n",
      "|  1.0  |  0.53  |   0.42   | 0.135  |    0.677     |     0.2565     |     0.1415     |     0.21     |  9.0  |\n",
      "|  1.0  |  0.44  |  0.365   | 0.125  |    0.516     |     0.2155     |     0.114      |    0.155     |  10.0 |\n",
      "|  1.0  |  0.33  |  0.255   |  0.08  |    0.205     |     0.0895     |     0.0395     |    0.055     |  7.0  |\n",
      "|  1.0  | 0.425  |   0.3    | 0.095  |    0.3515    |     0.141      |     0.0775     |     0.12     |  8.0  |\n",
      "|  1.0  |  0.53  |  0.415   |  0.15  |    0.7775    |     0.237      |     0.1415     |     0.33     |  20.0 |\n",
      "|  1.0  | 0.545  |  0.425   | 0.125  |    0.768     |     0.294      |     0.1495     |     0.26     |  16.0 |\n",
      "|  1.0  | 0.475  |   0.37   | 0.125  |    0.5095    |     0.2165     |     0.1125     |    0.165     |  9.0  |\n",
      "|  1.0  |  0.55  |   0.44   |  0.15  |    0.8945    |     0.3145     |     0.151      |     0.32     |  19.0 |\n",
      "+-------+--------+----------+--------+--------------+----------------+----------------+--------------+-------+\n"
     ]
    }
   ],
   "source": [
    "abalone_data = np.genfromtxt('./Datasets/Dataset.data', delimiter=' ') \n",
    "abalone_data = np.delete(abalone_data, 0, 1) #Delete sex because its NaN\n",
    "abalone_data = np.insert(abalone_data, 0, 1, axis = 1) #replace with all 1 for indep\n",
    "\n",
    "NbAttributes = np.shape(abalone_data)[1] #9 (counting indep)\n",
    "NbCases = np.shape(abalone_data)[0]      #4177\n",
    "lables = ['indep', 'length', 'diameter','height','whole_weight','Shucked_weight','viscera_weight','shell_weight', 'rings']\n",
    "\n",
    "t = PrettyTable(lables)\n",
    "for i in range(NbCases):\n",
    "    t.add_row( [abalone_data[i][j] for j in range(NbAttributes)] )\n",
    "\n",
    "print(t.get_string(start = 0, end = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Gradient Descent\n",
    "$$ \\theta_{j}  = \\theta_{j} - \\alpha\\frac{1}{m} \\sum_{i=1}^{m} [h_\\theta (X^{i}) - Y^{i}]*X_j^{i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NbVariables = NbAttributes - 1 #because the result is not considered a variable\n",
    "\n",
    "X = np.delete(abalone_data, NbVariables, 1) #only the parameters\n",
    "Y = abalone_data.T[NbAttributes-1].reshape(NbCases, 1) # Only the result which is the nb or rings as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the gradient correspondent to the cuadratic const function\n",
    "\n",
    "# Th is the previous value of Th we had as a vector containing many thetas\n",
    "# j is the index of Th we wish to upate, we will have to update all or some for stochastic gradient descent\n",
    "# X is a matrix with colums being the variables used for learning\n",
    "# Y is a column vecotr which gives the correct results for the parameters of X\n",
    "def gradient (Th, j, X, Y):\n",
    "    gradient = 0\n",
    "    \n",
    "    for i in range(NbCases):\n",
    "        gradient += np.dot( ( np.dot( Th, X[i] ) - Y[i] ), X[i][j] )[0]\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+----------+--------+----------+----------+----------+----------+\n",
      "|  k   | indep | length | diameter | height | w_weight | S_weight | v_weight | s_weight |\n",
      "+------+-------+--------+----------+--------+----------+----------+----------+----------+\n",
      "| 0.0  | 1.625 | 1.303  |   1.23   | 1.078  |  1.469   |  1.177   |   1.09   |  1.125   |\n",
      "| 1.0  | 2.112 | 1.536  |  1.407   | 1.138  |  1.824   |  1.309   |  1.159   |  1.221   |\n",
      "| 2.0  | 2.492 | 1.717  |  1.544   | 1.185  |   2.09   |  1.406   |   1.21   |  1.294   |\n",
      "| 3.0  | 2.791 | 1.856  |   1.65   | 1.221  |  2.288   |  1.477   |  1.248   |   1.35   |\n",
      "| 4.0  | 3.026 | 1.964  |  1.732   |  1.25  |  2.435   |  1.527   |  1.275   |  1.393   |\n",
      "| 5.0  | 3.213 | 2.048  |  1.796   | 1.272  |  2.542   |  1.561   |  1.296   |  1.426   |\n",
      "| 6.0  | 3.362 | 2.113  |  1.845   | 1.289  |  2.619   |  1.583   |   1.31   |  1.451   |\n",
      "| 7.0  | 3.483 | 2.164  |  1.884   | 1.302  |  2.672   |  1.597   |   1.32   |   1.47   |\n",
      "| 8.0  | 3.582 | 2.204  |  1.915   | 1.313  |  2.708   |  1.603   |  1.326   |  1.485   |\n",
      "| 9.0  | 3.664 | 2.236  |  1.939   | 1.322  |   2.73   |  1.604   |   1.33   |  1.496   |\n",
      "| 10.0 | 3.733 | 2.261  |  1.958   | 1.329  |  2.743   |  1.601   |  1.332   |  1.505   |\n",
      "| 11.0 | 3.791 | 2.282  |  1.974   | 1.335  |  2.747   |  1.595   |  1.332   |  1.511   |\n",
      "| 12.0 | 3.841 | 2.298  |  1.987   |  1.34  |  2.745   |  1.587   |  1.331   |  1.517   |\n",
      "| 13.0 | 3.886 | 2.312  |  1.997   | 1.344  |   2.74   |  1.576   |  1.329   |  1.521   |\n",
      "| 14.0 | 3.925 | 2.323  |  2.006   | 1.347  |   2.73   |  1.565   |  1.327   |  1.524   |\n",
      "| 15.0 | 3.961 | 2.333  |  2.014   |  1.35  |  2.719   |  1.553   |  1.324   |  1.526   |\n",
      "| 16.0 | 3.993 | 2.341  |   2.02   | 1.353  |  2.705   |   1.54   |  1.321   |  1.529   |\n",
      "| 17.0 | 4.024 | 2.348  |  2.026   | 1.355  |   2.69   |  1.526   |  1.317   |   1.53   |\n",
      "| 18.0 | 4.052 | 2.355  |  2.031   | 1.358  |  2.674   |  1.512   |  1.314   |  1.532   |\n",
      "| 19.0 | 4.079 |  2.36  |  2.035   |  1.36  |  2.658   |  1.498   |   1.31   |  1.533   |\n",
      "| 20.0 | 4.104 | 2.366  |   2.04   | 1.362  |  2.641   |  1.483   |  1.306   |  1.534   |\n",
      "| 21.0 | 4.129 |  2.37  |  2.044   | 1.364  |  2.624   |  1.469   |  1.302   |  1.535   |\n",
      "| 22.0 | 4.152 | 2.375  |  2.047   | 1.365  |  2.607   |  1.455   |  1.298   |  1.536   |\n",
      "| 23.0 | 4.175 | 2.379  |  2.051   | 1.367  |   2.59   |   1.44   |  1.294   |  1.538   |\n",
      "| 24.0 | 4.197 | 2.383  |  2.054   | 1.369  |  2.572   |  1.426   |   1.29   |  1.539   |\n",
      "| 25.0 | 4.218 | 2.387  |  2.058   | 1.371  |  2.555   |  1.411   |  1.286   |   1.54   |\n",
      "| 26.0 | 4.239 | 2.391  |  2.061   | 1.372  |  2.538   |  1.397   |  1.282   |  1.541   |\n",
      "| 27.0 |  4.26 | 2.395  |  2.064   | 1.374  |  2.522   |  1.383   |  1.278   |  1.542   |\n",
      "| 28.0 |  4.28 | 2.399  |  2.067   | 1.375  |  2.505   |  1.368   |  1.275   |  1.543   |\n",
      "| 29.0 | 4.299 | 2.402  |   2.07   | 1.377  |  2.489   |  1.354   |  1.271   |  1.544   |\n",
      "| 30.0 | 4.318 | 2.406  |  2.073   | 1.379  |  2.473   |   1.34   |  1.267   |  1.546   |\n",
      "| 31.0 | 4.337 | 2.409  |  2.076   |  1.38  |  2.457   |  1.326   |  1.263   |  1.547   |\n",
      "| 32.0 | 4.356 | 2.413  |  2.079   | 1.382  |  2.441   |  1.313   |   1.26   |  1.548   |\n",
      "| 33.0 | 4.374 | 2.416  |  2.082   | 1.383  |  2.426   |  1.299   |  1.256   |   1.55   |\n",
      "| 34.0 | 4.392 | 2.419  |  2.084   | 1.385  |  2.411   |  1.285   |  1.252   |  1.551   |\n",
      "| 35.0 | 4.409 | 2.422  |  2.087   | 1.386  |  2.396   |  1.272   |  1.249   |  1.553   |\n",
      "| 36.0 | 4.426 | 2.426  |   2.09   | 1.388  |  2.381   |  1.258   |  1.245   |  1.554   |\n",
      "| 37.0 | 4.443 | 2.429  |  2.093   | 1.389  |  2.367   |  1.245   |  1.242   |  1.556   |\n",
      "| 38.0 |  4.46 | 2.432  |  2.096   | 1.391  |  2.353   |  1.232   |  1.239   |  1.558   |\n",
      "| 39.0 | 4.476 | 2.435  |  2.098   | 1.392  |  2.339   |  1.219   |  1.235   |   1.56   |\n",
      "| 40.0 | 4.492 | 2.438  |  2.101   | 1.394  |  2.325   |  1.206   |  1.232   |  1.561   |\n",
      "| 41.0 | 4.508 | 2.441  |  2.104   | 1.395  |  2.312   |  1.193   |  1.229   |  1.563   |\n",
      "| 42.0 | 4.523 | 2.444  |  2.106   | 1.397  |  2.299   |   1.18   |  1.226   |  1.565   |\n",
      "| 43.0 | 4.538 | 2.447  |  2.109   | 1.398  |  2.286   |  1.168   |  1.223   |  1.567   |\n",
      "| 44.0 | 4.553 |  2.45  |  2.111   |  1.4   |  2.273   |  1.155   |  1.219   |  1.569   |\n",
      "| 45.0 | 4.568 | 2.453  |  2.114   | 1.401  |   2.26   |  1.143   |  1.216   |  1.571   |\n",
      "| 46.0 | 4.582 | 2.456  |  2.117   | 1.403  |  2.248   |   1.13   |  1.213   |  1.573   |\n",
      "| 47.0 | 4.596 | 2.459  |  2.119   | 1.404  |  2.236   |  1.118   |   1.21   |  1.575   |\n",
      "| 48.0 |  4.61 | 2.462  |  2.122   | 1.406  |  2.224   |  1.106   |  1.207   |  1.577   |\n",
      "| 49.0 | 4.624 | 2.464  |  2.124   | 1.407  |  2.212   |  1.094   |  1.205   |   1.58   |\n",
      "| 50.0 | 4.637 | 2.467  |  2.127   | 1.409  |  2.201   |  1.082   |  1.202   |  1.582   |\n",
      "| 51.0 |  4.65 |  2.47  |  2.129   |  1.41  |   2.19   |   1.07   |  1.199   |  1.584   |\n",
      "| 52.0 | 4.663 | 2.473  |  2.132   | 1.412  |  2.179   |  1.058   |  1.196   |  1.587   |\n",
      "| 53.0 | 4.676 | 2.475  |  2.134   | 1.413  |  2.168   |  1.046   |  1.193   |  1.589   |\n",
      "| 54.0 | 4.689 | 2.478  |  2.137   | 1.414  |  2.157   |  1.034   |  1.191   |  1.591   |\n",
      "| 55.0 | 4.701 | 2.481  |  2.139   | 1.416  |  2.147   |  1.023   |  1.188   |  1.594   |\n",
      "| 56.0 | 4.713 | 2.483  |  2.141   | 1.417  |  2.136   |  1.011   |  1.185   |  1.596   |\n",
      "| 57.0 | 4.725 | 2.486  |  2.144   | 1.419  |  2.126   |   1.0    |  1.183   |  1.599   |\n",
      "| 58.0 | 4.737 | 2.489  |  2.146   |  1.42  |  2.116   |  0.988   |   1.18   |  1.602   |\n",
      "| 59.0 | 4.748 | 2.491  |  2.149   | 1.422  |  2.107   |  0.977   |  1.178   |  1.604   |\n",
      "| 60.0 | 4.759 | 2.494  |  2.151   | 1.423  |  2.097   |  0.966   |  1.175   |  1.607   |\n",
      "| 61.0 | 4.771 | 2.496  |  2.153   | 1.425  |  2.088   |  0.954   |  1.173   |   1.61   |\n",
      "| 62.0 | 4.781 | 2.499  |  2.156   | 1.426  |  2.078   |  0.943   |   1.17   |  1.612   |\n",
      "| 63.0 | 4.792 | 2.501  |  2.158   | 1.427  |  2.069   |  0.932   |  1.168   |  1.615   |\n",
      "| 64.0 | 4.803 | 2.504  |   2.16   | 1.429  |  2.061   |  0.921   |  1.165   |  1.618   |\n",
      "| 65.0 | 4.813 | 2.506  |  2.163   |  1.43  |  2.052   |   0.91   |  1.163   |  1.621   |\n",
      "| 66.0 | 4.823 | 2.508  |  2.165   | 1.432  |  2.043   |   0.9    |  1.161   |  1.624   |\n",
      "| 67.0 | 4.833 | 2.511  |  2.167   | 1.433  |  2.035   |  0.889   |  1.158   |  1.627   |\n",
      "| 68.0 | 4.843 | 2.513  |  2.169   | 1.434  |  2.027   |  0.878   |  1.156   |   1.63   |\n",
      "| 69.0 | 4.852 | 2.515  |  2.172   | 1.436  |  2.018   |  0.868   |  1.154   |  1.633   |\n",
      "+------+-------+--------+----------+--------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Use the gradient of each parameter to update accordingly\n",
    "Th = np.ones(NbVariables) # Initialize to random values like all 1's\n",
    "Alph = 0.1\n",
    "m = NbCases\n",
    "\n",
    "iterations = 70\n",
    "\n",
    "### for printing the steps ###\n",
    "lables = ['k', 'indep', 'length', 'diameter', 'height', 'w_weight', 'S_weight', 'v_weight', 's_weight']\n",
    "t = PrettyTable(lables)\n",
    "\n",
    "for k in range(iterations):\n",
    "    NewTh = Th #Define a new th as placeholder because we want to update all at once\n",
    "    \n",
    "    for j in range(NbVariables):\n",
    "        NewTh[j] -= Alph/m * gradient(Th, j, X, Y)\n",
    "    \n",
    "    Th = NewTh\n",
    "    t.add_row(np.insert( np.round(Th, decimals=3), 0, k ) ) # Add to the printer table, prepend the step\n",
    "    \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how the values for the parameters are converging!\n",
    "### Now do the same, but without printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the gradient of each parameter to update accordingly\n",
    "Th = np.ones(NbVariables) # Initialize to random values like all 1's\n",
    "Alph = 0.001\n",
    "m = NbCases #should be nb of points in set\n",
    "\n",
    "iterations = 600\n",
    "\n",
    "for k in range(iterations):\n",
    "    NewTh = Th #Define a new th as placeholder because we want to update all at once\n",
    "    \n",
    "    for j in range(NbVariables):\n",
    "        NewTh[j] -= Alph/m * gradient(Th, j, X, Y)\n",
    "    \n",
    "    Th = NewTh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.01118761  2.04764488  1.8185001   1.28398417  2.60097833  1.64785212\n",
      "  1.34422998  1.491263  ]\n"
     ]
    }
   ],
   "source": [
    "# Now use the learned parameters to estiamate the age of some Abalones!\n",
    "print(Th)\n",
    "def getAge (Th, X, i):\n",
    "    return int(np.dot(X[i], Th)) #cast to int because, age is int?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| Exp | Real |\n",
      "+-----+------+\n",
      "|  7  | 8.0  |\n",
      "|  5  | 7.0  |\n",
      "|  7  | 10.0 |\n",
      "|  6  | 10.0 |\n",
      "|  6  | 7.0  |\n",
      "|  7  | 8.0  |\n",
      "|  6  | 8.0  |\n",
      "|  7  | 8.0  |\n",
      "|  4  | 4.0  |\n",
      "|  7  | 7.0  |\n",
      "|  6  | 7.0  |\n",
      "|  7  | 9.0  |\n",
      "|  7  | 10.0 |\n",
      "|  6  | 7.0  |\n",
      "|  7  | 8.0  |\n",
      "|  6  | 8.0  |\n",
      "|  8  | 12.0 |\n",
      "|  10 | 13.0 |\n",
      "|  6  | 10.0 |\n",
      "|  4  | 6.0  |\n",
      "|  8  | 13.0 |\n",
      "|  5  | 8.0  |\n",
      "|  10 | 20.0 |\n",
      "|  10 | 11.0 |\n",
      "|  9  | 13.0 |\n",
      "|  9  | 15.0 |\n",
      "|  9  | 9.0  |\n",
      "|  8  | 10.0 |\n",
      "|  8  | 11.0 |\n",
      "|  9  | 14.0 |\n",
      "|  9  | 9.0  |\n",
      "|  11 | 12.0 |\n",
      "|  9  | 16.0 |\n",
      "|  10 | 21.0 |\n",
      "|  9  | 14.0 |\n",
      "|  10 | 12.0 |\n",
      "|  10 | 13.0 |\n",
      "|  8  | 10.0 |\n",
      "|  6  | 9.0  |\n",
      "|  9  | 12.0 |\n",
      "|  8  | 15.0 |\n",
      "|  8  | 12.0 |\n",
      "|  9  | 13.0 |\n",
      "|  10 | 10.0 |\n",
      "|  11 | 15.0 |\n",
      "|  11 | 14.0 |\n",
      "|  7  | 9.0  |\n",
      "|  6  | 8.0  |\n",
      "|  6  | 7.0  |\n",
      "|  7  | 10.0 |\n",
      "+-----+------+\n"
     ]
    }
   ],
   "source": [
    "t = PrettyTable(['Exp', 'Real'])\n",
    "\n",
    "for i in range(NbCases):\n",
    "    t.add_row( [ getAge(Th, X, i), Y[i][0]] )\n",
    "    \n",
    "print(t.get_string(start = 50, end = 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That is amazing!\n",
    "### And see how fast that is\n",
    "This particular training set took around a minute to update 600 times\n",
    "\n",
    "It might improve with more computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
